{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 机器学习在定位上的应用：https://cloud.tencent.com/developer/news/701639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle  \n",
    "\n",
    "# 加载数据集\n",
    "def load_data(data_path, shuff=True):\n",
    "    data = pd.read_csv(data_path)\n",
    "    data = data.fillna(-1)  # Nan值填充\n",
    "#     print(data.iloc[1000])\n",
    "    if shuff:   # 将数据集打乱\n",
    "        data = shuffle(data)\n",
    "#     print(data.iloc[1000])\n",
    "    # 构建数据集和标签\n",
    "    samples = []\n",
    "    labels = []\n",
    "    for index, row in data.iterrows():\n",
    "    # print(row) # 输出每行的索引值\n",
    "        matrix = []  # 7 * 4\n",
    "        for i in range(7):\n",
    "            matrix.append([i+1,\n",
    "                           row['AsuLevel_' + str(i+1)],\n",
    "                           row['SignalLevel_' + str(i+1)],\n",
    "                           row['Dbm_' + str(i+1)]]) # 新数据集中不存在RSSI，使用Dbm(代功率的绝对值)\n",
    "        # print(matrix)\n",
    "        samples.append(matrix)\n",
    "        labels.append([row['Longitude'], row['Latitude']])\n",
    "    return np.array(samples), np.array(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = r\"../data/siping_4g.csv\"\n",
    "samples, labels = load_data(path)\n",
    "print(samples[0], labels[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(samples.shape)\n",
    "print(labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 数据变形： (3479, 7, 4)---》 (3479, 7, 4，1)\n",
    "samples = samples.reshape(-1, 7,4,1) # -1自动计算"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 划分数据集\n",
    "x_train, x_test, y_train, y_test = train_test_split(samples, labels, test_size=0.2)  #划分训练数据、训练标签、验证数据、验证标签\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "\n",
    "# print(x_test[100])\n",
    "# print(y_test[100])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 尝试在竞争对手中的前10%，只需要多走一步\n",
    "\n",
    "from keras.utils import np_utils # keras中numpy工具包\n",
    "from keras.models import Sequential\n",
    "# 二维卷积 数据池化  数据扁平化(reshape)\n",
    "from keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten, Dropout\n",
    "# 优化器\n",
    "# from keras.optimizers import Adam\n",
    "from keras.optimizers import adam_v2\n",
    "\n",
    "# 换为one-hot格式\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=121)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=121)\n",
    "\n",
    "# 定义顺序模型\n",
    "model = Sequential()\n",
    "\n",
    "# 第一个卷积层\n",
    "# input_shape 输入数据的形状(平面)，只要在第一层进行设置\n",
    "\"\"\"\n",
    "    filters, 卷积核/滤波器的个数\n",
    "    kernel_size, 卷积核\n",
    "    strides=(1, 1),  步长\n",
    "    padding='valid',  填充方式\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,  激活函数\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "\"\"\"\n",
    "model.add(\n",
    "    Convolution2D(\n",
    "        input_shape = (7, 4,1),\n",
    "        filters = 32,\n",
    "        kernel_size = 3,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# 第一个池化层:不需要输入形状 28*28 --> 28*28（same填充方式）\n",
    "model.add(\n",
    "    MaxPooling2D(\n",
    "        pool_size=2,\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "    )\n",
    ")\n",
    "\n",
    "# 第二个卷积层 池化之后 28/2  28*28--> 14*14\n",
    "model.add(Convolution2D(64,5, strides=1, padding='same', activation='relu'))\n",
    "\n",
    "# 第二个池化层  14*14\n",
    "model.add(MaxPooling2D(2,2,'same'))\n",
    "\n",
    "# 把第二个池化层的输出扁平化为一维   7*7\n",
    "model.add(Flatten()) # 7*7  --> 64*7*7\n",
    "\n",
    "# 第一个全连接层 \n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "# Dropout防止过拟合\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 第2个全连接层\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# 定义优化器  loss 交叉熵\n",
    "# adam = Adam(lr=1e-4)\n",
    "lr = 1e-3\n",
    "adam = adam_v2.Adam(learning_rate=lr)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10)\n",
    "\n",
    "# 评估模型\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)\n",
    "\n",
    "loss, accuracy = model.evaluate(x_train, y_train)\n",
    "print('train loss: ', loss)\n",
    "print('train accuracy: ', accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "# 数据预处理\n",
    "path = r\"../data/siping_4g.csv\"\n",
    "\n",
    "\n",
    "# 将MR数据构建为7*4的矩阵\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "matrix = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    print(row) # 输出每行的索引值\n",
    "    for i in range(7):\n",
    "        matrix.append([i+1,\n",
    "                       row['AsuLevel_' + str(i+1)],\n",
    "                       row['SignalLevel_' + str(i+1)],\n",
    "                       row['Dbm_' + str(i+1)]]) # 新数据集中不存在RSSI，使用Dbm(代功率的绝对值)\n",
    "    print(matrix)\n",
    "    break\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def preprocess(path):\n",
    "    data = pd.read_csv(path)\n",
    "    # 对经纬度进行归一化的处理\n",
    "    print(data.head(1))\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(data[['Longitude', 'Latitude']].values)\n",
    "    return scaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.  56.   4. -84.]\n",
      " [  2.  49.   4. -91.]\n",
      " [  3.  42.   3. -98.]\n",
      " [  4.  43.   3. -97.]\n",
      " [  5.  -1.  -1.  -1.]\n",
      " [  6.  -1.  -1.  -1.]\n",
      " [  7.  -1.  -1.  -1.]] [121.4963968   31.28344556]\n"
     ]
    }
   ],
   "source": [
    "path = r\"../data/siping_4g.csv\"\n",
    "samples, labels = load_data(path)\n",
    "print(samples[0], labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3479, 7, 4)\n",
      "(3479, 2)\n"
     ]
    }
   ],
   "source": [
    "print(samples.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据变形： (3479, 7, 4)---》 (3479, 7, 4，1)\n",
    "samples = samples.reshape(-1, 7,4,1) # -1自动计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2783\n",
      "2783\n",
      "[[[  1.]\n",
      "  [ 60.]\n",
      "  [  4.]\n",
      "  [-80.]]\n",
      "\n",
      " [[  2.]\n",
      "  [ 58.]\n",
      "  [  4.]\n",
      "  [-82.]]\n",
      "\n",
      " [[  3.]\n",
      "  [ 59.]\n",
      "  [  4.]\n",
      "  [-81.]]\n",
      "\n",
      " [[  4.]\n",
      "  [ 59.]\n",
      "  [  4.]\n",
      "  [-81.]]\n",
      "\n",
      " [[  5.]\n",
      "  [ 46.]\n",
      "  [  4.]\n",
      "  [-94.]]\n",
      "\n",
      " [[  6.]\n",
      "  [ -1.]\n",
      "  [ -1.]\n",
      "  [ -1.]]\n",
      "\n",
      " [[  7.]\n",
      "  [ -1.]\n",
      "  [ -1.]\n",
      "  [ -1.]]]\n",
      "[121.4966909   31.28661194]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 划分数据集\n",
    "x_train, x_test, y_train, y_test = train_test_split(samples, labels, test_size=0.2)  #划分训练数据、训练标签、验证数据、验证标签\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "\n",
    "# print(x_test[100])\n",
    "# print(y_test[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 37.0 GiB for an array with shape (82165292, 121) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-87-b93999b3c485>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;31m# 换为one-hot格式\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m \u001B[0my_train\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_categorical\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_classes\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m121\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m \u001B[0my_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_categorical\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_classes\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m121\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\utils\\np_utils.py\u001B[0m in \u001B[0;36mto_categorical\u001B[1;34m(y, num_classes, dtype)\u001B[0m\n\u001B[0;32m     72\u001B[0m     \u001B[0mnum_classes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     73\u001B[0m   \u001B[0mn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 74\u001B[1;33m   \u001B[0mcategorical\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_classes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     75\u001B[0m   \u001B[0mcategorical\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     76\u001B[0m   \u001B[0moutput_shape\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minput_shape\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mnum_classes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 37.0 GiB for an array with shape (82165292, 121) and data type float32"
     ]
    }
   ],
   "source": [
    "# 尝试在竞争对手中的前10%，只需要多走一步\n",
    "\n",
    "from keras.utils import np_utils # keras中numpy工具包\n",
    "from keras.models import Sequential\n",
    "# 二维卷积 数据池化  数据扁平化(reshape)\n",
    "from keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten, Dropout\n",
    "# 优化器\n",
    "# from keras.optimizers import Adam\n",
    "from keras.optimizers import adam_v2\n",
    "\n",
    "# 换为one-hot格式\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=121)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=121)\n",
    "\n",
    "# 定义顺序模型\n",
    "model = Sequential()\n",
    "\n",
    "# 第一个卷积层\n",
    "# input_shape 输入数据的形状(平面)，只要在第一层进行设置\n",
    "\"\"\"\n",
    "    filters, 卷积核/滤波器的个数\n",
    "    kernel_size, 卷积核\n",
    "    strides=(1, 1),  步长\n",
    "    padding='valid',  填充方式\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,  激活函数\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "\"\"\"\n",
    "model.add(\n",
    "    Convolution2D(\n",
    "        input_shape = (7, 4,1),\n",
    "        filters = 32,\n",
    "        kernel_size = 3,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# 第一个池化层:不需要输入形状 28*28 --> 28*28（same填充方式）\n",
    "model.add(\n",
    "    MaxPooling2D(\n",
    "        pool_size=2,\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "    )\n",
    ")\n",
    "\n",
    "# 第二个卷积层 池化之后 28/2  28*28--> 14*14\n",
    "model.add(Convolution2D(64,5, strides=1, padding='same', activation='relu'))\n",
    "\n",
    "# 第二个池化层  14*14\n",
    "model.add(MaxPooling2D(2,2,'same'))\n",
    "\n",
    "# 把第二个池化层的输出扁平化为一维   7*7\n",
    "model.add(Flatten()) # 7*7  --> 64*7*7\n",
    "\n",
    "# 第一个全连接层 \n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "# Dropout防止过拟合\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 第2个全连接层\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# 定义优化器  loss 交叉熵\n",
    "# adam = Adam(lr=1e-4)\n",
    "lr = 1e-3\n",
    "adam = adam_v2.Adam(learning_rate=lr)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\engine\\training.py:789 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\losses.py:1666 categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\backend.py:4839 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 2, 122, 121) and (None, 121) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-88-9f0513ebbb67>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# 训练模型\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# 评估模型\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccuracy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1182\u001B[0m                 _r=1):\n\u001B[0;32m   1183\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1184\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1185\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1186\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    883\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    884\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 885\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    886\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    887\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    922\u001B[0m       \u001B[1;31m# In this case we have not created variables on the first call. So we can\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    923\u001B[0m       \u001B[1;31m# run the first trace but we should fail if variables are created.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 924\u001B[1;33m       \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    925\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_created_variables\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    926\u001B[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001B[1;32mD:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3036\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3037\u001B[0m       (graph_function,\n\u001B[1;32m-> 3038\u001B[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0m\u001B[0;32m   3039\u001B[0m     return graph_function._call_flat(\n\u001B[0;32m   3040\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001B[1;32mD:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m   3458\u001B[0m               call_context_key in self._function_cache.missed):\n\u001B[0;32m   3459\u001B[0m             return self._define_function_with_shape_relaxation(\n\u001B[1;32m-> 3460\u001B[1;33m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001B[0m\u001B[0;32m   3461\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3462\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_define_function_with_shape_relaxation\u001B[1;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001B[0m\n\u001B[0;32m   3380\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3381\u001B[0m     graph_function = self._create_graph_function(\n\u001B[1;32m-> 3382\u001B[1;33m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001B[0m\u001B[0;32m   3383\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marg_relaxed\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mrank_only_cache_key\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3384\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[0;32m   3306\u001B[0m             \u001B[0marg_names\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0marg_names\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3307\u001B[0m             \u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3308\u001B[1;33m             capture_by_value=self._capture_by_value),\n\u001B[0m\u001B[0;32m   3309\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_function_attributes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3310\u001B[0m         \u001B[0mfunction_spec\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunction_spec\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001B[0m\n\u001B[0;32m   1005\u001B[0m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1006\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1007\u001B[1;33m       \u001B[0mfunc_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1008\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1009\u001B[0m       \u001B[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m    666\u001B[0m         \u001B[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    667\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcompile_with_xla\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 668\u001B[1;33m           \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    669\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    670\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    992\u001B[0m           \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint:disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    993\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"ag_error_metadata\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 994\u001B[1;33m               \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    995\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    996\u001B[0m               \u001B[1;32mraise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\engine\\training.py:789 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\losses.py:1666 categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\keras\\backend.py:4839 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    D:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 2, 122, 121) and (None, 121) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10)\n",
    "\n",
    "# 评估模型\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)\n",
    "\n",
    "loss, accuracy = model.evaluate(x_train, y_train)\n",
    "print('train loss: ', loss)\n",
    "print('train accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrajID                    0\n",
      "IMEI            8.62305e+14\n",
      "IMSI            4.60091e+14\n",
      "MRTime          1.52179e+12\n",
      "Longitude           121.496\n",
      "                   ...     \n",
      "Unnamed: 126            NaN\n",
      "Unnamed: 127            NaN\n",
      "Unnamed: 128            NaN\n",
      "Unnamed: 129            NaN\n",
      "Unnamed: 130            NaN\n",
      "Name: 0, Length: 131, dtype: object\n",
      "[[1, 68, 4, -72], [2, 60.0, 4.0, -80.0], [3, 51.0, 4.0, -89.0], [4, -1.0, -1.0, -1.0], [5, -1.0, -1.0, -1.0], [6, -1.0, -1.0, -1.0], [7, -1.0, -1.0, -1.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "# 数据预处理\n",
    "path = r\"../data/siping_4g.csv\"\n",
    "\n",
    "\n",
    "# 将MR数据构建为7*4的矩阵\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "matrix = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    print(row) # 输出每行的索引值\n",
    "    for i in range(7):\n",
    "        matrix.append([i+1,\n",
    "                       row['AsuLevel_' + str(i+1)],\n",
    "                       row['SignalLevel_' + str(i+1)],\n",
    "                       row['Dbm_' + str(i+1)]]) # 新数据集中不存在RSSI，使用Dbm(代功率的绝对值)\n",
    "    print(matrix)\n",
    "    break\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def preprocess(path):\n",
    "    data = pd.read_csv(path)\n",
    "    # 对经纬度进行归一化的处理\n",
    "    print(data.head(1))\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(data[['Longitude', 'Latitude']].values)\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mode'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mD:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   2897\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2898\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2899\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'mode'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-4f59a45795e4>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     46\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mm_d\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 48\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmode_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-10-4f59a45795e4>\u001B[0m in \u001B[0;36mmode_dict\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m     33\u001B[0m     \u001B[0mm_d\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     34\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mtrajid\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtraj\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtrajs\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 35\u001B[1;33m         \u001B[0mmd\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtraj\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'mode'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     36\u001B[0m         \u001B[0mloc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtraj\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Longitude'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'Latitude'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m         \u001B[0mtl\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtraj\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'MRTime'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2904\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2905\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2906\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2907\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2908\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\AppData\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   2898\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2899\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2900\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2901\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2902\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mtolerance\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'mode'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import math\n",
    "\n",
    "\n",
    "def compute_time_interval(timestamp1, timestamp2):\n",
    "    dateArray1 = datetime.datetime.utcfromtimestamp(timestamp1 / 1000)\n",
    "    dateArray2 = datetime.datetime.utcfromtimestamp(timestamp2 / 1000)\n",
    "    # otherStyleTime = dateArray1.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return float((dateArray2 - dateArray1).seconds)\n",
    "\n",
    "def distance(true_pt, pred_pt):\n",
    "    lat1 = float(true_pt[1])\n",
    "    lng1 = float(true_pt[0])\n",
    "    lat2 = float(pred_pt[1])\n",
    "    lng2 = float(pred_pt[0])\n",
    "    radLat1 = rad(lat1)\n",
    "    radLat2 = rad(lat2)\n",
    "    a = radLat1 - radLat2\n",
    "    b = rad(lng1) - rad(lng2)\n",
    "    s = 2 * math.asin(math.sqrt(math.pow(math.sin(a / 2), 2) +\n",
    "                                math.cos(radLat1) * math.cos(radLat2) * math.pow(math.sin(b / 2), 2)))\n",
    "    s = s * 6378.137\n",
    "    s = round(s * 10000) / 10\n",
    "    return s\n",
    "\n",
    "def mode_dict(path):\n",
    "#     path = data_dict[drname]\n",
    "    data = pd.read_csv(path)\n",
    "    trajs = data.groupby([\"TrajID\"])\n",
    "    m_d = {}\n",
    "    m_d[0] = []\n",
    "    m_d[1] = []\n",
    "    m_d[2] = []\n",
    "    for trajid, traj in trajs:\n",
    "        md = list(traj['mode'])\n",
    "        loc = traj[['Longitude', 'Latitude']].values\n",
    "        tl = list(traj['MRTime'])\n",
    "        for j in range(1, traj.shape[0]):\n",
    "            if j > 0:\n",
    "                delta_t = compute_time_interval(tl[j - 1], tl[j])\n",
    "                delta_s = distance(loc[j - 1, :], loc[j, :])\n",
    "                m = int(md[j])\n",
    "                if delta_t > 0:\n",
    "                    m_d[m].append(delta_s / delta_t)\n",
    "\n",
    "    return m_d\n",
    "\n",
    "print(mode_dict(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}